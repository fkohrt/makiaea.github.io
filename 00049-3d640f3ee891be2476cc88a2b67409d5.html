<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/>
<title>3d640f3ee891be2476cc88a2b67409d5</title>
<script type="text/javascript">
function showhide(id)
{
    var e = document.getElementById(id);
    e.style.display = (e.style.display == 'block') ? 'none' : 'block';
}
</script>
<style>
rect {
transition: .6s fill;
fill: #D3D3D3;
opacity: 0;
}
rect:hover {
    fill: #D3D3D3;
    opacity: 0.2;
}

.outline {
    clear: both;
}

.svg-container {
    width: 100%;
    max-width: 4122px;
    margin-left: auto;
    margin-right: auto;
    display: block;
}

.svg-content {
    width: 100%;
}

.container {
    width: 100%;
}
</style>

</head>

<body>

<div class="container"><div class="spacer">&nbsp;</div><div class="svg-container"><svg version="1.1"  preserveAspectRatio="xMinYMin meet" class="svg-content" viewBox="0 0 4122 15318" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<image width="4122" height="15318" xlink:href="00049-3d640f3ee891be2476cc88a2b67409d5-assets/00049-3d640f3ee891be2476cc88a2b67409d5.png"></image>
<a xlink:href="00049-3d640f3ee891be2476cc88a2b67409d5.html" xlink:title="00049-3d640f3ee891be2476cc88a2b67409d5.html"><rect x="1798" y="4519" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00149"><rect x="1798" y="4679" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00249"><rect x="1798" y="4783" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00349"><rect x="1798" y="5499" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00449"><rect x="1798" y="6495" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00549"><rect x="1798" y="7063" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00649"><rect x="1798" y="7385" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00749"><rect x="1798" y="7529" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00849"><rect x="1798" y="7615" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/00949"><rect x="1798" y="7695" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01049"><rect x="1798" y="7775" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01149"><rect x="1798" y="7855" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01249"><rect x="1798" y="7935" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01349"><rect x="1798" y="8015" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01449"><rect x="1798" y="8095" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01549"><rect x="1798" y="8175" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01649"><rect x="1798" y="8255" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01749"><rect x="1798" y="8335" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01849"><rect x="1798" y="8415" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/01949"><rect x="1798" y="8495" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02049"><rect x="1798" y="8575" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02149"><rect x="1798" y="8655" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02249"><rect x="1798" y="8735" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02349"><rect x="1798" y="8815" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02449"><rect x="1798" y="8895" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02549"><rect x="1798" y="8975" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02649"><rect x="1798" y="9055" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02749"><rect x="1798" y="9135" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02849"><rect x="1798" y="9215" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/02949"><rect x="1798" y="9295" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03049"><rect x="1798" y="9375" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03149"><rect x="1798" y="9455" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03249"><rect x="1798" y="9535" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03349"><rect x="1798" y="9615" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03449"><rect x="1798" y="9695" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03549"><rect x="1798" y="9775" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03649"><rect x="1798" y="9855" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03749"><rect x="1798" y="9935" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03849"><rect x="1798" y="10015" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/03949"><rect x="1798" y="10095" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04049"><rect x="1798" y="10175" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04149"><rect x="1798" y="10255" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04249"><rect x="1798" y="10335" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04349"><rect x="1798" y="10415" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04449"><rect x="1798" y="10495" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04549"><rect x="1798" y="10575" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04649"><rect x="1798" y="10655" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04749"><rect x="1798" y="10735" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04849"><rect x="1798" y="10821" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/04949"><rect x="1798" y="10907" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05049"><rect x="2166" y="670" width="28" height="28"/></a>
<a xlink:href="https://doi.org/10.3758/s13423-016-1198-z" xlink:title="https://doi.org/10.3758/s13423-016-1198-z"><rect x="2826" y="367" width="526" height="33"/></a>
<a xlink:href="https://doi.org/10.1287/stsc.2017.0048" xlink:title="https://doi.org/10.1287/stsc.2017.0048"><rect x="2826" y="528" width="473" height="33"/></a>
<a xlink:href="https://aeon.co/essays/are-humans-really-blind-to-the-gorilla-on-the-basketball-court" xlink:title="https://aeon.co/essays/are-humans-really-blind-to-the-gorilla-on-the-basketball-court"><rect x="2826" y="208" width="564" height="33"/></a>
<a xlink:href="https://aeon.co/essays/are-humans-really-blind-to-the-gorilla-on-the-basketball-court" xlink:title="https://aeon.co/essays/are-humans-really-blind-to-the-gorilla-on-the-basketball-court"><rect x="2826" y="241" width="425" height="33"/></a>
<a xlink:href="https://doi.org/10.3758/s13423-017-1333-5" xlink:title="https://doi.org/10.3758/s13423-017-1333-5"><rect x="2826" y="688" width="530" height="33"/></a>
<a xlink:href="https://doi.org/10.1016/j.neuron.2018.07.032" xlink:title="https://doi.org/10.1016/j.neuron.2018.07.032"><rect x="2810" y="1076" width="541" height="33"/></a>
<a xlink:href="https://doi.org/10.1016/j.neuron.2018.07.038" xlink:title="https://doi.org/10.1016/j.neuron.2018.07.038"><rect x="2810" y="1236" width="541" height="33"/></a>
<a xlink:href="https://www.inverse.com/article/48300-why-is-it-hard-to-focus-research-humans" xlink:title="https://www.inverse.com/article/48300-why-is-it-hard-to-focus-research-humans"><rect x="2810" y="882" width="576" height="33"/></a>
<a xlink:href="https://www.inverse.com/article/48300-why-is-it-hard-to-focus-research-humans" xlink:title="https://www.inverse.com/article/48300-why-is-it-hard-to-focus-research-humans"><rect x="2810" y="916" width="371" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05149"><rect x="2166" y="1480" width="28" height="28"/></a>
<a xlink:href="http://www.theverge.com/2017/4/10/15245690/how-emotions-are-made-neuroscience-lisa-feldman-barrett" xlink:title="http://www.theverge.com/2017/4/10/15245690/how-emotions-are-made-neuroscience-lisa-feldman-barrett"><rect x="2412" y="1447" width="556" height="67"/></a>
<a xlink:href="http://www.theverge.com/2017/4/10/15245690/how-emotions-are-made-neuroscience-lisa-feldman-barrett" xlink:title="http://www.theverge.com/2017/4/10/15245690/how-emotions-are-made-neuroscience-lisa-feldman-barrett"><rect x="2412" y="1515" width="73" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05249"><rect x="2166" y="2036" width="28" height="28"/></a>
<a xlink:href="https://www.theguardian.com/lifeandstyle/2017/apr/11/vision-thing-how-babies-colour-in-the-world?CMP=share_btn_fb" xlink:title="https://www.theguardian.com/lifeandstyle/2017/apr/11/vision-thing-how-babies-colour-in-the-world?CMP=share_btn_fb"><rect x="2412" y="1760" width="576" height="33"/></a>
<a xlink:href="https://www.theguardian.com/lifeandstyle/2017/apr/11/vision-thing-how-babies-colour-in-the-world?CMP=share_btn_fb" xlink:title="https://www.theguardian.com/lifeandstyle/2017/apr/11/vision-thing-how-babies-colour-in-the-world?CMP=share_btn_fb"><rect x="2412" y="1794" width="431" height="33"/></a>
<a xlink:href="https://aeon.co/essays/can-we-hope-to-understand-how-the-greeks-saw-their-world" xlink:title="https://aeon.co/essays/can-we-hope-to-understand-how-the-greeks-saw-their-world"><rect x="2412" y="2024" width="548" height="33"/></a>
<a xlink:href="https://aeon.co/essays/can-we-hope-to-understand-how-the-greeks-saw-their-world" xlink:title="https://aeon.co/essays/can-we-hope-to-understand-how-the-greeks-saw-their-world"><rect x="2412" y="2058" width="370" height="33"/></a>
<a xlink:href="http://dx.doi.org/10.1016/j.cub.2017.12.014" xlink:title="http://dx.doi.org/10.1016/j.cub.2017.12.014"><rect x="2412" y="2187" width="527" height="33"/></a>
<a xlink:href="http://dx.doi.org/10.1038/s41598-018-25433-5" xlink:title="http://dx.doi.org/10.1038/s41598-018-25433-5"><rect x="2412" y="2348" width="568" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05349"><rect x="2166" y="2554" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05449"><rect x="2166" y="2940" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.7554/eLife.18103" xlink:title="http://dx.doi.org/10.7554/eLife.18103"><rect x="2412" y="2796" width="140" height="33"/></a>
<a xlink:href="https://aeon.co/ideas/how-your-mind-under-stress-gets-better-at-processing-bad-news" xlink:title="https://aeon.co/ideas/how-your-mind-under-stress-gets-better-at-processing-bad-news"><rect x="2412" y="2956" width="544" height="33"/></a>
<a xlink:href="https://aeon.co/ideas/how-your-mind-under-stress-gets-better-at-processing-bad-news" xlink:title="https://aeon.co/ideas/how-your-mind-under-stress-gets-better-at-processing-bad-news"><rect x="2412" y="2990" width="501" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05549"><rect x="2166" y="3262" width="28" height="28"/></a>
<a xlink:href="https://aeon.co/ideas/how-the-cute-pikachu-is-a-chocolate-milkshake-for-the-brain" xlink:title="https://aeon.co/ideas/how-the-cute-pikachu-is-a-chocolate-milkshake-for-the-brain"><rect x="2794" y="3247" width="568" height="33"/></a>
<a xlink:href="https://aeon.co/ideas/how-the-cute-pikachu-is-a-chocolate-milkshake-for-the-brain" xlink:title="https://aeon.co/ideas/how-the-cute-pikachu-is-a-chocolate-milkshake-for-the-brain"><rect x="2794" y="3281" width="140" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05649"><rect x="2166" y="3484" width="28" height="28"/></a>
<a xlink:href="http://doi.org/10.1073/pnas.1506552113" xlink:title="http://doi.org/10.1073/pnas.1506552113"><rect x="2402" y="3586" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05749"><rect x="2166" y="3796" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1126/science.aaf6005" xlink:title="http://dx.doi.org/10.1126/science.aaf6005"><rect x="2652" y="3768" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1126/science.aaf5656" xlink:title="http://dx.doi.org/10.1126/science.aaf5656"><rect x="2662" y="3904" width="195" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05849"><rect x="2166" y="4090" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1177/0956797616661182" xlink:title="http://dx.doi.org/10.1177/0956797616661182"><rect x="2402" y="4176" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/05949"><rect x="2166" y="4338" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1016/j.ssresearch.2016.08.007" xlink:title="http://dx.doi.org/10.1016/j.ssresearch.2016.08.007"><rect x="2402" y="4424" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06049"><rect x="2166" y="4508" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06149"><rect x="2166" y="4662" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1177/0956797616667721" xlink:title="http://dx.doi.org/10.1177/0956797616667721"><rect x="2402" y="4730" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06249"><rect x="2166" y="4878" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1177/1368430216677304" xlink:title="http://dx.doi.org/10.1177/1368430216677304"><rect x="2402" y="4946" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06349"><rect x="2166" y="5066" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1073/pnas.1617357114" xlink:title="http://dx.doi.org/10.1073/pnas.1617357114"><rect x="2412" y="5084" width="457" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06449"><rect x="2166" y="5226" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1016/j.jrp.2017.03.005" xlink:title="http://dx.doi.org/10.1016/j.jrp.2017.03.005"><rect x="2412" y="5244" width="440" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06549"><rect x="2166" y="5436" width="28" height="28"/></a>
<a xlink:href="https://aeon.co/essays/how-real-magic-happens-when-the-brain-sees-hidden-things" xlink:title="https://aeon.co/essays/how-real-magic-happens-when-the-brain-sees-hidden-things"><rect x="2412" y="5472" width="580" height="33"/></a>
<a xlink:href="https://aeon.co/essays/how-real-magic-happens-when-the-brain-sees-hidden-things" xlink:title="https://aeon.co/essays/how-real-magic-happens-when-the-brain-sees-hidden-things"><rect x="2412" y="5505" width="336" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06649"><rect x="2166" y="5664" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1037/xge0000240" xlink:title="http://dx.doi.org/10.1037/xge0000240"><rect x="2412" y="5698" width="150" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06749"><rect x="2166" y="6622" width="28" height="28"/></a>
<a xlink:href="https://doi.org/10.1371/journal.pcbi.1005684" xlink:title="https://doi.org/10.1371/journal.pcbi.1005684"><rect x="2412" y="6656" width="450" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06849"><rect x="2166" y="7522" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/06949"><rect x="2166" y="7602" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07049"><rect x="2166" y="8413" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1111/tops.12312" xlink:title="http://dx.doi.org/10.1111/tops.12312"><rect x="2412" y="9122" width="443" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07149"><rect x="2166" y="9282" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1037/pspi0000114" xlink:title="http://dx.doi.org/10.1037/pspi0000114"><rect x="2412" y="9316" width="394" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07249"><rect x="2166" y="9478" width="28" height="28"/></a>
<a xlink:href="https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth" xlink:title="https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth"><rect x="2412" y="9478" width="568" height="33"/></a>
<a xlink:href="https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth" xlink:title="https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth"><rect x="2412" y="9512" width="524" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07349"><rect x="2166" y="9640" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1177/0956797617743018" xlink:title="http://dx.doi.org/10.1177/0956797617743018"><rect x="2412" y="9641" width="556" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07449"><rect x="2166" y="9818" width="28" height="28"/></a>
<a xlink:href="http://psycnet.apa.org/doi/10.1037/apl0000247" xlink:title="http://psycnet.apa.org/doi/10.1037/apl0000247"><rect x="2412" y="9870" width="567" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07549"><rect x="2166" y="10012" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1177/1948550617741181" xlink:title="http://dx.doi.org/10.1177/1948550617741181"><rect x="2412" y="10030" width="556" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07649"><rect x="2166" y="10132" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07749"><rect x="2166" y="10252" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1126/science.aap8731" xlink:title="http://dx.doi.org/10.1126/science.aap8731"><rect x="2412" y="10270" width="511" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07849"><rect x="2166" y="10372" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/07949"><rect x="2166" y="10452" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08049"><rect x="2166" y="10532" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08149"><rect x="2166" y="10612" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08249"><rect x="2166" y="10692" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08349"><rect x="2166" y="10772" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08449"><rect x="2166" y="10852" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08549"><rect x="2166" y="10932" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08649"><rect x="2166" y="11012" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08749"><rect x="2166" y="11150" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1177/0146167218779823" xlink:title="http://dx.doi.org/10.1177/0146167218779823"><rect x="2412" y="11184" width="556" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08849"><rect x="2166" y="11288" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/08949"><rect x="2166" y="11368" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09049" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09049"><rect x="2166" y="11568" width="28" height="28"/></a>
<a xlink:href="http://dx.doi.org/10.1016/j.neuron.2017.11.008" xlink:title="http://dx.doi.org/10.1016/j.neuron.2017.11.008"><rect x="2412" y="11506" width="563" height="33"/></a>
<a xlink:href="http://dx.doi.org/10.1073/pnas.1801512115" xlink:title="http://dx.doi.org/10.1073/pnas.1801512115"><rect x="2412" y="11666" width="528" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09149" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09149"><rect x="2166" y="11956" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09249" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09249"><rect x="2166" y="12224" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09349" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09349"><rect x="2166" y="12362" width="28" height="28"/></a>
<a xlink:href="https://aeon.co/ideas/how-cotton-production-in-medieval-china-unravelled-patriarchy" xlink:title="https://aeon.co/ideas/how-cotton-production-in-medieval-china-unravelled-patriarchy"><rect x="2412" y="12362" width="568" height="33"/></a>
<a xlink:href="https://aeon.co/ideas/how-cotton-production-in-medieval-china-unravelled-patriarchy" xlink:title="https://aeon.co/ideas/how-cotton-production-in-medieval-china-unravelled-patriarchy"><rect x="2412" y="12396" width="423" height="33"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09449" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09449"><rect x="2166" y="12500" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09549" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09549"><rect x="2166" y="12580" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09649" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09649"><rect x="2166" y="12660" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09749" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09749"><rect x="2166" y="13922" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09849" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09849"><rect x="2166" y="15184" width="28" height="28"/></a>
<a xlink:href="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09949" xlink:title="file:///var/mobile/Library/Mobile%20Documents/iCloud~com~toketaware~ios~ithoughts/Documents/09949"><rect x="2166" y="15264" width="28" height="28"/></a>
</svg>
</div>
</div>

<br/>
<a href="javascript:showhide('outlineDiv')">Outline show/hide</a>
<div id="outlineDiv" style="display:none;">
<h1>00049</h1>
<p>candy</p>
<h2>05049</h2>
<ul>
<li>fallacy of obviousness
<ul>
<li>
<p><em>the fallacy of obviousness: a new interpretation of a classic psychology experiment will change your view of perception, judgment – even human nature</em><br />
teppo felin 2018<br />
<a href="https://aeon.co/essays/are-humans-really-blind-to-the-gorilla-on-the-basketball-court">https://aeon.co/essays/are-humans-really-blind-to-the-gorilla-on-the-basketball-court</a></p>
<ul>
<li>
<p>“computers and algorithms – even the most sophisticated ones – cannot address the fallacy of obviousness. Put differently, they can never know what might be relevant.”</p>
<p>“while Kahneman calls for large-scale replications of priming studies, the argument here is not that we need more studies or data to verify that people indeed miss blatantly obvious gorillas. Instead, we need better interpretation and better theories. After all, additional studies and data would undoubtedly verify the gorilla finding. But the more important issue is the interpretation of the gorilla finding and the experimental construction of the finding.</p>
<p>Having a ‘blind to the obvious’-baseline assumption about human nature biases the types of experiments that are crafted by scientists in the first place, what scientists go on to observe and look for, and how they interpret what they find. And importantly, the assumption of human blindness or bias makes scientists themselves blind to the other, more positive aspects of human cognition and nature. Thus the problem is more upstream, in the set of a priori questions and theories that science has. Namely, if our theory focuses on some aspect of human blindness and bias, and if we construct lab experiments to prove it (or look for naturally occurring instances of it), then yes, we are likely to find evidence.”</p>
<p>“Any well-intentioned efforts to correct human blindness also need to recognise that making these corrections comes with costs or tradeoffs. The trivial point here is that if we want to correct for the blindness of not spotting something (such as the gorilla), then this correction comes at the cost of attending to any number of other obvious things (eg, number of basketball passes). But the far more important point is that we also need to recognise and investigate the remarkable human capacities for generating questions and theories that direct our awareness and observations in the first place. Bias and blindness-obsessed studies will never get us to this vital recognition. In other words, continuing to construct experiments that look for and show bias and blindness – and adding them to the very large and growing list of cognitive biases and forms of blindness – will always leave out the remarkable capacities of humans to generate questions and theories. At its worst, the fascination with blindness and bias flattens humans, and science, to a morally dubious game of ‘gotcha’.”</p>
</li>
</ul>
</li>
<li>
<p><em>rationality, perception, and the all-seeing eye</em><br />
teppo felin et al. 2016<br />
<a href="https://doi.org/10.3758/s13423-016-1198-z">https://doi.org/10.3758/s13423-016-1198-z</a></p>
<ul>
<li>Seeing—perception and vision—is implicitly the fundamental building block of the literature on rationality and cognition. Herbert Simon and Daniel Kahneman’s arguments against the omniscience of economic agents—and the concept of bounded rationality—depend critically on a particular view of the nature of perception and vision. We propose that this framework of rationality merely replaces economic omniscience with perceptual omniscience. We show how the cognitive and social sciences feature a pervasive but problematic meta-assumption that is characterized by an “all-seeing eye.” We raise concerns about this assumption and discuss different ways in which the all-seeing eye manifests itself in existing research on (bounded) rationality. We first consider the centrality of vision and perception in Simon’s pioneering work. We then point to Kahneman’s work—particularly his article “Maps of Bounded Rationality”—to illustrate the pervasiveness of an all-seeing view of perception, as manifested in the extensive use of visual examples and illusions. Similar assumptions about perception can be found across a large literature in the cognitive sciences. The central problem is the present emphasis on inverse optics—the objective nature of objects and environments, e.g., size, contrast, and color. This framework ignores the nature of the organism and perceiver. We argue instead that reality is constructed and expressed, and we discuss the species-specificity of perception, as well as perception as a user interface. We draw on vision science as well as the arts to develop an alternative understanding of rationality in the cognitive and social sciences. We conclude with a discussion of the implications of our arguments for the rationality and decision-making literature in cognitive psychology and behavioral economics, along with suggesting some ways forward.</li>
</ul>
</li>
<li>
<p><em>the theory-based view: economic actors as theorists</em><br />
teppo felin and todd r. zenger 2017<br />
<a href="https://doi.org/10.1287/stsc.2017.0048">https://doi.org/10.1287/stsc.2017.0048</a></p>
<ul>
<li>This paper outlines the theory-based view of strategy and markets. We argue that novel or “great” strategies come from theories. Entrepreneurs and managers originate theories and hypotheses about which activities they should engage in, which assets they might buy, and how they will create value. A firm’s strategy, then, represents a set of contrarian beliefs and a theory—a unique, firm-specific point of view—about what problems to solve, and how to organize and govern the overall process of value creation. We outline the cognitive and perceptual, organizational, and economic foundations of the theory-based view of strategy. We also discuss the essential attributes needed for a firm-level theory of strategy. Throughout the paper we offer informal examples of our argument, by briefly discussing the strategies of companies like Apple, Uber, Disney, Wal-Mart, and Airbnb. The theory-based view of strategy and markets also offers important insights for how firms govern themselves (including ownership, boards, and organization design) and how firms interact with capital markets and external evaluators and stakeholders. We conclude with a discussion of the practical and managerial applications of the theory-based view.</li>
</ul>
</li>
<li>
<p><em>mind, rationality, and cognition: an interdisciplinary debate</em><br />
nick chater et al. 2017<br />
<a href="https://doi.org/10.3758/s13423-017-1333-5">https://doi.org/10.3758/s13423-017-1333-5</a></p>
<ul>
<li>This article features an interdisciplinary debate and dialogue about the nature of mind, perception, and rationality. Scholars from a range of disciplines—cognitive science, applied and experimental psychology, behavioral economics, and biology—offer critiques and commentaries of a target article by Felin, Koenderink, and Krueger (<u>2017</u>): “Rationality, Perception, and the All-Seeing Eye,” <em>Psychonomic Bulletin &amp; Review</em>. The commentaries raise a number of criticisms and issues concerning rationality and the all-seeing-eye argument, including the nature of judgment and reasoning, biases versus heuristics, organism–environment relations, perception and situational construal, equilibrium analysis in economics, efficient markets, and the nature of empirical observation and the scientific method. The debated topics have far-reaching consequences for the rationality literature specifically, as well as for the cognitive, psychological, and economic sciences more broadly. The commentaries are followed by a response from the authors of the target article. Their response is organized around three central issues: (1) the problem of cues; (2) what is the question?; and (3) equilibria, $500 bills, and the axioms of rationality.</li>
</ul>
</li>
</ul>
</li>
<li>punctuated attention
<ul>
<li>
<p><em>scientists reveal the number of times you’re actually conscious each minute: spoiler: it’s not very often (and that’s a good thing)</em><br />
emma betuel 2018<br />
<a href="https://www.inverse.com/article/48300-why-is-it-hard-to-focus-research-humans">https://www.inverse.com/article/48300-why-is-it-hard-to-focus-research-humans</a></p>
<ul>
<li>
<p>Four times every second, explains Princeton Neuroscience Institute Ian Fiebelkorn, Ph.D., to Inverse, the brain stops focusing on the task at hand. That’s about 240 times a minute.</p>
<p>“The brain is wired to be somewhat distractible.”</p>
<p>“The brain is wired to be somewhat distractible,” he says. “We focus in bursts, and between those bursts we have these periods of distractibility, that’s when the brain seems to check in on the rest of the environment outside to see if there’s something important going on elsewhere. These rhythms are affecting our behavior all the time.”<br />
To understand these “rhythms of attention,” Fiebelkorn suggests imagining standing in Times Square on New Years’ Eve, surrounded by people, cars, and music. The scene presents far more sensory information than one human brain is capable of sorting through, and so, the brain deals with all of the information in two ways. First, it focuses on a single point of interest: the street corner where you might meet a friend, or Ryan Seacrest combing the crowd for interviews. Like a filmstrip, the brain takes snapshots of these moments and pieces them together into a cohesive narrative, or “perceptual cycle.”</p>
<p>We experience that moment as continuous, but in reality, we’ve only sampled certain elements of the environment around us. It feels continuous because our brains have filled in the gaps for us, explains Berkeley’s Knight Lab researcher and first author Randolph Helfrich, Ph.D. to Inverse.</p>
<p>“I think it’s more a philosophical problem that it is a scientific problem,” he says. “Because when we look at brain data we see a pattern that waxes and wanes, they’re never constant and stable. Everyone perceives the world as continuous and coherent, but the real tricky part is, how does the brain do that?”</p>
<p>Modern society tends to think of distractibility as a bad thing, Fiebelkorn says, but it might have offered early humans and our distant ancestors a huge evolutionary advantage. The brain’s natural tendency to “zoom out” and become distracted by the environment, even for just a few milliseconds, could have allowed them the time to detect the presence of a threat and react accordingly.</p>
<p>“Say you spot a shiny red apple in a tree and you focus on that,” Fiebelkorn says. “You’re going to go and pick that apple, but you’ll want to know if there’s any larger animal with bigger teeth going after the same apple. So, having these windows of distractibility helps you to detect these stimuli you might otherwise miss.”</p>
<p>The findings of these two papers in conjunction are powerful evidence that these rhythms are highly adaptive and have been preserved in humans and their relative species for millions of years. This hypothesis is based on the fact that the teams noticed nearly identical neural patterns of attention (the “rhythms of distractability”) in both the humans and macaques. For a trait to still be so similar in species that diverged from a common ancestor billions of years ago, it very likely must provide a useful evolutionary advantage that has been preserved by natural selection.</p>
</li>
</ul>
</li>
<li>
<p><em>neural mechanisms of sustained attention are rhythmic</em><br />
randolph f. helfrich et al. 2018<br />
<a href="https://doi.org/10.1016/j.neuron.2018.07.032">https://doi.org/10.1016/j.neuron.2018.07.032</a></p>
<ul>
<li>
<p>“Our subjective experience of the visual world is an illusion,” said Sabine Kastner, a professor of psychology and the Princeton Neuroscience Institute (PNI). “Perception is discontinuous, going rhythmically through short time windows when we can perceive more or less.”<br />
The researchers use different metaphors to describe this throb of attention, including a spotlight that waxes and wanes in its intensity. Four times per second — once every 250 milliseconds — the spotlight dims and the house lights come up. Instead of focusing on the action “onstage,” your brain takes in everything else around you, say the scientists.<br />
Their work appears as a set of back-to-back papers in in the Aug. 22 issue of <em>Neuron</em>; one paper focuses on human research subjects, the other on macaque monkeys.<br />
“The question is: How can something that varies in time support our seemingly continuous perception of the world?” said Berkeley’s Randolph Helfrich, first author on the human-focused paper. “There are only two options: Is the data wrong, or is our understanding of our perception biased? Our research shows that it’s the latter. Our brains fuse our perceptions into a coherent movie — we don’t experience the gaps.”<br />
Perception doesn’t flicker on and off, the researchers emphasized, but four times per second it cycles between periods of maximum focus and periods of a broader situational awareness.<br />
“Every 250 milliseconds, you have an opportunity to switch attention,” said Ian Fiebelkorn, an associate research scholar in PNI and the first author on the macaque-focused paper. You won’t necessarily shift your focus to a new subject, he said, but your brain has a chance to re-examine your priorities and decide if it wants to.<br />
Brain rhythms have been known for almost a century, since electroencephalograms — better known as EEGs — were invented in 1924. “But we didn’t really understand what these rhythms are for,” said Kastner, who was the senior author on both papers. “We can now link brain rhythms for the first time to our behavior, on a moment-to-moment basis. ... This is a very surprising finding, more since these rhythmic processes are evolutionarily old — we find them in non-human primates as well as in our own species.”<br />
This pulsing attention must present an evolutionary advantage, the researchers suggest, perhaps because focusing too intently on one subject could allow a threat to catch us by surprise.<br />
“Attention is fluid, and you want it to be fluid,” said Fiebelkorn. “You don’t want to be over-locked on anything. It seems like it’s an evolutionary advantage to have these windows of opportunity where you’re checking in with your environment.”<br />
“It’s an elegant way to allocate brain resources — to sample the environment and not have any lapses,” said Robert Knight, a professor of psychology and neuroscience at Berkeley and a co-author on the human-focused paper.<br />
Kastner’s lab focuses on macaque research, so she reached out to Knight’s lab, which does similar studies on humans. The resulting papers are unprecedented, Knight said.<br />
“This is cross-species validation of a fundamental aspect of human behavior,” he said. “I have not seen any back-to-back human and monkey papers appear anywhere ... and these are in the same issue of <em>Neuron</em>, a preeminent journal.”<br />
Fiebelkorn agreed: “We have an assumption that what we find in the monkey will hold up in humans, but it’s rarely checked as carefully as it is here.”<br />
“Originally, we wanted to study something very different,” said Kastner. “We wanted to ask how we can select objects from our cluttered visual environments. ... We were particularly looking at how the intake of visual information unfolds over time — something that is rarely done in behavioral studies — and this revealed the rhythmic structure of perception. It was a complete surprise finding.”</p>
</li>
<li>
<p><em>abstract</em> The functional architecture of attention is rhythmic<br />
Frontoparietal theta activity predicts behavior on a rapid timescale<br />
Theta activity controls cortical excitability and information flow<br />
Rhythmic sampling is independent of task structure and context</p>
<p>Classic models of attention suggest that sustained neural firing constitutes a neural correlate of sustained attention. However, recent evidence indicates that behavioral performance fluctuates over time, exhibiting temporal dynamics that closely resemble the spectral features of ongoing, oscillatory brain activity. Therefore, it has been proposed that periodic neuronal excitability fluctuations might shape attentional allocation and overt behavior. However, empirical evidence to support this notion is sparse. Here, we address this issue by examining data from large-scale subdural recordings, using two different attention tasks that track perceptual ability at high temporal resolution. Our results reveal that perceptual outcome varies as a function of the theta phase even in states of sustained spatial attention. These effects were robust at the single-subject level, suggesting that rhythmic perceptual sampling is an inherent property of the frontoparietal attention network. Collectively, these findings support the notion that the functional architecture of top-down attention is intrinsically rhythmic.</p>
</li>
</ul>
</li>
<li>
<p><em>a dynamic interplay within the frontoparietal network underlies rhythmic spatial attention</em><br />
ian c. fiebelkorn et al. 2018<br />
<a href="https://doi.org/10.1016/j.neuron.2018.07.038">https://doi.org/10.1016/j.neuron.2018.07.038</a></p>
<ul>
<li>
<p><em>abstract</em> Non-human primates, like humans, sample the visual scene in rhythmic cycles<br />
Neural oscillations in the frontoparietal network modulate perceptual sensitivity<br />
Theta phase acts as a clocking mechanism, organizing alternating attentional states<br />
Temporal dynamics linked to specific function and cell type define attentional state</p>
<p>Classic studies of spatial attention assumed that its neural and behavioral effects were continuous over time. Recent behavioral studies have instead revealed that spatial attention leads to alternating periods of heightened or diminished perceptual sensitivity. Yet, the neural basis of these rhythmic fluctuations has remained largely unknown. We show that a dynamic interplay within the macaque frontoparietal network accounts for the rhythmic properties of spatial attention. Neural oscillations characterize functional interactions between the frontal eye fields (FEF) and the lateral intraparietal area (LIP), with theta phase (3–8 Hz) coordinating two rhythmically alternating states. The first is defined by FEF-dominated beta-band activity, associated with suppressed attentional shifts, and LIP-dominated gamma-band activity, associated with enhanced visual processing and better behavioral performance. The second is defined by LIP-specific alpha-band activity, associated with attenuated visual processing and worse behavioral performance. Our findings reveal how network-level interactions organize environmental sampling into rhythmic cycles.</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>05149</h2>
<ul>
<li>
<p>neuroscientist lisa feldman barrett explains how emotions are made 2017<br />
<a href="http://www.theverge.com/2017/4/10/15245690/how-emotions-are-made-neuroscience-lisa-feldman-barrett">theverge.com/2017/4/10/15245690/how-emotions-are-made-neuroscience-lisa-feldman-barrett</a></p>
<ul>
<li>I think understanding how emotions are constructed widens the horizon of control. You realize that if your brain is using your past to construct your present, you can invest energy in the present to cultivate new experiences that then become the seeds for your future. You can cultivate or curate experiences in the now and then they become, if you practice them, they become automated enough that your brain will automatically construct them in the future.</li>
</ul>
</li>
</ul>
<h2>05249</h2>
<ul>
<li>
<p><em>the vision thing: how babies colour in the world</em><br />
nicola davis 2017<br />
<a href="https://www.theguardian.com/lifeandstyle/2017/apr/11/vision-thing-how-babies-colour-in-the-world?CMP=share_btn_fb">theguardian.com/lifeandstyle/2017/apr/11/vision-thing-how-babies-colour-in-the-world</a></p>
</li>
<li>
<p><em>the sea was never blue</em><br />
the greek colour experience was made of movement and shimmer. can we ever glimpse what they saw when gazing out to sea?<br />
maria michela sassi 2017<br />
<a href="https://aeon.co/essays/can-we-hope-to-understand-how-the-greeks-saw-their-world">aeon.co/essays/can-we-hope-to-understand-how-the-greeks-saw-their-world</a></p>
</li>
<li>
<p><em>hunter-gatherer olfaction is special</em><br />
majid and kruspe 2018<br />
<a href="http://dx.doi.org/10.1016/j.cub.2017.12.014">http://dx.doi.org/10.1016/j.cub.2017.12.014</a></p>
<ul>
<li>
<p>•People struggle to name odors, but this limitation is not universal<br />
•Is superior olfactory performance due to subsistence, ecology or language family?<br />
•Hunter-gatherers and non-hunter-gatherers from the same environment were compared<br />
•Only hunter-gatherers were proficient odor namers, showing subsistence is crucial</p>
<p>People struggle to name odors. This has been attributed to a diminution of olfaction in trade-off to vision. This presumption has been challenged recently by data from the hunter-gatherer Jahai who, unlike English speakers, find odors as easy to name as colors. Is the superior olfactory performance among the Jahai because of their ecology (tropical rainforest), their language family (Aslian), or because of their subsistence (they are hunter-gatherers)? We provide novel evidence from the hunter-gatherer Semaq Beri and the non-hunter-gatherer (swidden-horticulturalist) Semelai that subsistence is the critical factor. Semaq Beri and Semelai speakers—who speak closely related languages and live in the tropical rainforest of the Malay Peninsula—took part in a controlled odor- and color-naming experiment. The swidden-horticulturalist Semelai found odors much more difficult to name than colors, replicating the typical Western finding. But for the hunter-gatherer Semaq Beri odor naming was as easy as color naming, suggesting that hunter-gatherer olfactory cognition is special.</p>
</li>
</ul>
</li>
<li>
<p><em>spatial representations of the viewer’s surroundings</em><br />
satoshi shioiri et al. 2018<br />
<a href="http://dx.doi.org/10.1038/s41598-018-25433-5">http://dx.doi.org/10.1038/s41598-018-25433-5</a></p>
<ul>
<li>
<p>Spatial representation surrounding a viewer including outside the visual field is crucial for moving around the three-dimensional world. To obtain such spatial representations, we predict that there is a learning process that integrates visual inputs from different viewpoints covering all the 360° visual angles. We report here the learning effect of the spatial layouts on six displays arranged to surround the viewer, showing shortening of visual search time on surrounding layouts that are repeatedly used (contextual cueing effect). The learning effect is found even in the time to reach the display with the target as well as the time to reach the target within the target display, which indicates that there is an implicit learning effect on spatial configurations of stimulus elements across displays. Since, furthermore, the learning effect is found between layouts and the target presented on displays located even 120° apart, this effect should be based on the representation that covers visual information far outside the visual field.</p>
</li>
<li>
<p>contextual cueing effect (CCE),<br />
CCE of surrounds (CCES)</p>
<p>the visual system constructs representations that link information within the visual field and information outside the visual field through repeated observation of the same spatial arrangements, that is, the CCES. The CCES is implicit and done without awareness of repeated observation of the same stimulus. Representations obtained by repetition without awareness are useful for moving around in familiar spaces and also in spaces that have structures in common with familiar places. Such representations should support actions in everyday life as well as specific actions for sports, driving, and so on.</p>
</li>
</ul>
</li>
</ul>
<h2>05349</h2>
<ul>
<li>“experiences vs things”
<ul>
<li>
<p><em>stuffocation</em><br />
james wallman 20 978-0-9575245-2-1</p>
</li>
<li>
<p>“experiences are more prone to positive reinterpretation, less likely to be dulled by hedonic adaptation, harder to compare, more likely to contribute to identity, and they bring you closer to people.”</p>
</li>
</ul>
</li>
</ul>
<h2>05449</h2>
<ul>
<li>
<p><em>unexpected arousal modulates the influence of sensory noise on confidence</em><br />
micah allen et al. 2016<br />
<a href="http://dx.doi.org/10.7554/eLife.18103">eLife.18103</a></p>
<ul>
<li>“relevant to understanding clinical disorders, such as anxiety and depression, where changes in arousal might lock sufferers into an unrealistically certain or uncertain world”</li>
<li>Human perception is invariably accompanied by a graded feeling of confidence that guides metacognitive awareness and decision-making. It is often assumed that this arises solely from the feed-forward encoding of the strength or precision of sensory inputs. In contrast, interoceptive inference models suggest that confidence reflects a weighted integration of sensory precision and expectations about internal states, such as arousal. Here we test this hypothesis using a novel psychophysical paradigm, in which unseen disgust-cues induced unexpected, unconscious arousal just before participants discriminated motion signals of variable precision. Across measures of perceptual bias, uncertainty, and physiological arousal we found that arousing disgust cues modulated the encoding of sensory noise. Furthermore, the degree to which trial-by-trial pupil fluctuations encoded this nonlinear interaction correlated with trial level confidence. Our results suggest that unexpected arousal regulates perceptual precision, such that subjective confidence reflects the integration of both external sensory and internal, embodied states.</li>
</ul>
</li>
<li>
<p><em>how your mind, under stress, gets better at processing bad news</em><br />
tali sharot 2018<br />
<a href="https://aeon.co/ideas/how-your-mind-under-stress-gets-better-at-processing-bad-news">https://aeon.co/ideas/how-your-mind-under-stress-gets-better-at-processing-bad-news</a></p>
</li>
<li>
<p><em>the influential mind: what the brain reveals about our power to change others</em><br />
tali sharot 2017</p>
</li>
</ul>
<h2>05549</h2>
<ul>
<li>supernormal stimuli
<ul>
<li><em>pikachu is a chocolate milkshake</em><br />
joel frohlich 2016<br />
<a href="https://aeon.co/ideas/how-the-cute-pikachu-is-a-chocolate-milkshake-for-the-brain">how-the-cute-pikachu-is-a-chocolate-milkshake-for-the-brain</a></li>
</ul>
</li>
</ul>
<h2>05649</h2>
<ul>
<li>
<p><em>covert digital manipulation of vocal emotion alter speakers’ emotional states in a congruent direction</em><br />
jean-julien aucouturier, petter johansson, lars hall, rodrigo segnini, lolita mercadié, and katsumi watanabe 2016<br />
http://doi.org/10.1073/pnas.1506552113<br />
Link: <a href="http://doi.org/10.1073/pnas.1506552113">doi.org/10.1073/pnas.1506552113</a></p>
<ul>
<li>
<p><em>Significance</em><br />
We created a digital audio platform to covertly modify the emotional tone of participants’ voices while they talked toward happiness, sadness, or fear. Independent listeners perceived the transformations as natural examples of emotional speech, but the participants remained unaware of the manipulation, indicating that we are not continuously monitoring our own emotional signals. Instead, as a consequence of listening to their altered voices, the emotional state of the participants changed in congruence with the emotion portrayed. This result is the first evidence, to our knowledge, of peripheral feedback on emotional experience in the auditory domain. This finding is of great significance, because the mechanisms behind the production of vocal emotion are virtually unknown.</p>
</li>
<li>
<p><em>Abstract</em><br />
Research has shown that people often exert control over their emotions. By modulating expressions, reappraising feelings, and redirecting attention, they can regulate their emotional experience. These findings have contributed to a blurring of the traditional boundaries between cognitive and emotional processes, and it has been suggested that emotional signals are produced in a goal-directed way and monitored for errors like other intentional actions. However, this interesting possibility has never been experimentally tested. To this end, we created a digital audio platform to covertly modify the emotional tone of participants’ voices while they talked in the direction of happiness, sadness, or fear. The result showed that the audio transformations were being perceived as natural examples of the intended emotions, but the great majority of the participants, nevertheless, remained unaware that their own voices were being manipulated. This finding indicates that people are not continuously monitoring their own voice to make sure that it meets a predetermined emotional target. Instead, as a consequence of listening to their altered voices, the emotional state of the participants changed in congruence with the emotion portrayed, which was measured by both self-report and skin conductance level. This change is the first evidence, to our knowledge, of peripheral feedback effects on emotional experience in the auditory domain. As such, our result reinforces the wider framework of self-perception theory: that we often use the same inferential strategies to understand ourselves as those that we use to understand others.</p>
</li>
</ul>
</li>
</ul>
<h2>05749</h2>
<ul>
<li>sensing
<ul>
<li>
<p><em>phytochromes function as thermosensors in arabidopsis</em><br />
jae-hoon jung et al. 2016<br />
http://dx.doi.org/10.1126/science.aaf6005<br />
Link: <a href="http://dx.doi.org/10.1126/science.aaf6005">dx.doi.org/10.1126/science.aaf6005</a></p>
<ul>
<li>Plants are responsive to temperature, and can distinguish differences of 1°C. In <em>Arabidopsis</em>, warmer temperature accelerates flowering and increases elongation growth (thermomorphogenesis). The mechanisms of temperature perception are however largely unknown. We describe a major thermosensory role for the phytochromes (red light receptors) during the night. Phytochrome null plants display a constitutive warm temperature response, and consistent with this, we show in this background that the warm temperature transcriptome becomes de-repressed at low temperatures. We have discovered phytochrome B (phyB) directly associates with the promoters of key target genes in a temperature dependent manner. The rate of phyB inactivation is proportional to temperature in the dark, enabling phytochromes to function as thermal timers, integrating temperature information over the course of the night.</li>
</ul>
</li>
<li>
<p><em>phytochrome b integrates light and temperature signals in arabidopsis</em><br />
martina legris et al. 2016<br />
<a href="http://dx.doi.org/10.1126/science.aaf5656">science.aaf5656</a></p>
<ul>
<li>Ambient temperature regulates many aspects of plant growth and development but its sensors are unknown. Here, we demonstrate that the phytochrome B (phyB) photoreceptor participates in temperature perception through its temperature-dependent reversion from the active Pfr state to the inactive Pr state. Increased rates of thermal reversion upon exposing <em>Arabidopsis</em> seedlings to warm environments reduce both the abundance of the biologically active Pfr-Pfr dimer pool of phyB and the size of the associated nuclear bodies, even in daylight. Mathematical analysis of stem growth for seedlings expressing wild-type phyB or thermally stable variants under various combinations of light and temperature revealed that phyB is physiologically responsive to both signals. We therefore propose that in addition to its photoreceptor functions, phyB is a temperature sensor in plants.</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>05849</h2>
<ul>
<li>
<p><em>young children see a single action and infer a social norm: promiscuous normativity in 3-year-olds</em><br />
marco f. h. schmidt, lucas p. butler, julia heinz, and michael tomasello 2016<br />
http://dx.doi.org/10.1177/0956797616661182<br />
Link: <a href="http://dx.doi.org/10.1177/0956797616661182">dx.doi.org/10.1177/0956797616661182</a></p>
<ul>
<li>Human social life depends heavily on social norms that prescribe and proscribe specific actions. Typically, young children learn social norms from adult instruction. In the work reported here, we showed that this is not the whole story: Three-year-old children are promiscuous normativists. In other words, they spontaneously inferred the presence of social norms even when an adult had done nothing to indicate such a norm in either language or behavior. And children of this age even went so far as to enforce these self-inferred norms when third parties “broke” them. These results suggest that children do not just passively acquire social norms from adult behavior and instruction; rather, they have a natural and proactive tendency to go from “is” to “ought.” That is, children go from observed actions to prescribed actions and do not perceive them simply as guidelines for their own behavior but rather as objective normative rules applying to everyone equally.</li>
</ul>
</li>
</ul>
<h2>05949</h2>
<ul>
<li>
<p><em>the racialized construction of exceptionality: experimental evidence of race/ethnicity effects on teachers' interventions</em><br />
rachel elizabeth fish 2016<br />
http://dx.doi.org/10.1016/j.ssresearch.2016.08.007<br />
Link: <a href="http://dx.doi.org/10.1016/j.ssresearch.2016.08.007">dx.doi.org/10.1016/j.ssresearch.2016.08.007</a></p>
<ul>
<li>Scholars, policy-makers, and practitioners have long argued that students of color are over-represented in special education and under-represented in gifted education, arguing that educators make racially/ethnically biased decisions to refer and qualify students with disabilities and giftedness. Recent research has called this into question, focusing on the role of confounders of race/ethnicity. However, the role of educator decisions in the disproportionality is still unclear. In this study, I examine the role of student race/ethnicity in teachers' categorization of student needs as “exceptional” and in need of special or gifted education services. I use an original survey experiment in which teachers read case studies of fictional male students in which the race/ethnicity, English Language Learner status, and exceptionality characteristics were experimentally manipulated. The teachers are then asked whether they would refer the student for exceptionality testing. My findings suggest a complex intersection of race/ethnicity and exceptionality, in which white boys are more likely to be suspected of having exceptionalities when they exhibit academic challenges, while boys of color are more likely to be suspected when they exhibit behavioral challenges. This suggests that the racialized construction of exceptionalities reflects differential academic expectations and interpretations of behavior by race/ethnicity, with implications for the subjectivity of exceptionality identification and for the exacerbation of racial/ethnic inequalities in education.</li>
</ul>
</li>
</ul>
<h2>06049</h2>
<ul>
<li><em>how to lie with statistics</em><br />
darrel huff 1954</li>
</ul>
<h2>06149</h2>
<ul>
<li>
<p><em>social class and the motivational relevance of other human beings: evidence from visual attention</em><br />
p. dietze, e. d. knowles 2016<br />
http://dx.doi.org/10.1177/0956797616667721<br />
Link: <a href="http://dx.doi.org/10.1177/0956797616667721">dx.doi.org/10.1177/0956797616667721</a></p>
<ul>
<li>We theorize that people’s social class affects their appraisals of others’ motivational relevance—the degree to which others are seen as potentially rewarding, threatening, or otherwise worth attending to. Supporting this account, three studies indicate that social classes differ in the amount of attention their members direct toward other human beings. In Study 1, wearable technology was used to film the visual fields of pedestrians on city streets; higher-class participants looked less at other people than did lower-class participants. In Studies 2a and 2b, participants’ eye movements were tracked while they viewed street scenes; higher class was associated with reduced attention to people in the images. In Study 3, a change-detection procedure assessed the degree to which human faces spontaneously attract visual attention; faces proved less effective at drawing the attention of high-class than low-class participants, which implies that class affects spontaneous relevance appraisals. The measurement and conceptualization of social class are discussed.</li>
</ul>
</li>
</ul>
<h2>06249</h2>
<ul>
<li>
<p><em>the threat of increasing diversity: why many white americans support trump in the 2016 presidential election</em><br />
b. major, a. blodorn, g. major blascovich 2016<br />
http://dx.doi.org/10.1177/1368430216677304<br />
Link: <a href="http://dx.doi.org/10.1177/1368430216677304">dx.doi.org/10.1177/1368430216677304</a></p>
<ul>
<li>What accounts for the widespread support for Donald Trump in the 2016 U.S. presidential race? This experiment demonstrates that the changing racial demographics of America contribute to Trump’s success as a presidential candidate among White Americans whose race/ethnicity is central to their identity. Reminding White Americans high in ethnic identification that non-White racial groups will outnumber Whites in the United States by 2042 caused them to become more concerned about the declining status and influence of White Americans as a group (i.e., experience group status threat), and caused them to report increased support for Trump and anti-immigrant policies, as well as greater opposition to political correctness. Increased group status threat mediated the effects of the racial shift condition on candidate support, anti-immigrant policy support, and opposition to political correctness. Among Whites low in ethnic identification, in contrast, the racial shift condition had no effect on group status threat or support for anti-immigrant policies, but did cause decreased positivity toward Trump and decreased opposition to political correctness. Group status threat did not mediate these effects. Reminders of the changing racial demographics had comparable effects for Democrats and Republicans. Results illustrate the importance of changing racial demographics and White ethnic identification in voter preferences and how social psychological theory can illuminate voter preferences.</li>
</ul>
</li>
</ul>
<h2>06349</h2>
<ul>
<li>
<p><em>behavioral and neural correlates to multisensory detection of sick humans</em><br />
christina regenbogen et al. 2017<br />
<a href="http://dx.doi.org/10.1073/pnas.1617357114">dx.doi.org/10.1073/pnas.1617357114</a></p>
<ul>
<li>
<p>In the perpetual race between evolving organisms and pathogens, the human immune system has evolved to reduce the harm of infections. As part of such a system, avoidance of contagious individuals would increase biological fitness. The present study shows that we can detect both facial and olfactory cues of sickness in others just hours after experimental activation of their immune system. The study further demonstrates that multisensory integration of these olfactory and visual sickness cues is a crucial mechanism for how we detect and socially evaluate sick individuals. Thus, by motivating the avoidance of sick conspecifics, olfactory–visual cues, both in isolation and integrated, may be important parts of circuits handling imminent threats of contagion.</p>
<p>Throughout human evolution, infectious diseases have been a primary cause of death. Detection of subtle cues indicating sickness and avoidance of sick conspecifics would therefore be an adaptive way of coping with an environment fraught with pathogens. This study determines how humans perceive and integrate early cues of sickness in conspecifics sampled just hours after the induction of immune system activation, and the underlying neural mechanisms for this detection. In a double-blind placebo-controlled crossover design, the immune system in 22 sample donors was transiently activated with an endotoxin injection [lipopolysaccharide (LPS)]. Facial photographs and body odor samples were taken from the same donors when “sick” (LPS-injected) and when “healthy” (saline-injected) and subsequently were presented to a separate group of participants (<em>n</em> = 30) who rated their liking of the presented person during fMRI scanning. Faces were less socially desirable when sick, and sick body odors tended to lower liking of the faces. Sickness status presented by odor and facial photograph resulted in increased neural activation of odor- and face-perception networks, respectively. A superadditive effect of olfactory–visual integration of sickness cues was found in the intraparietal sulcus, which was functionally connected to core areas of multisensory integration in the superior temporal sulcus and orbitofrontal cortex. Taken together, the results outline a disease-avoidance model in which neural mechanisms involved in the detection of disease cues and multisensory integration are vital parts.</p>
</li>
</ul>
</li>
</ul>
<h2>06449</h2>
<ul>
<li>
<p><em>seeing it both ways: openness to experience and binocular rivalry suppression</em><br />
anna antinori, olivia l. carter, luke d. smillie 2017<br />
<a href="http://dx.doi.org/10.1016/j.jrp.2017.03.005">dx.doi.org/10.1016/j.jrp.2017.03.005</a></p>
<ul>
<li>
<p>Demonstrates personality and mood can impact low-level perceptual experiences.<br />
Mixed percept, a binocular rivalry state, positively correlated with openness.<br />
Findings were replicated across samples and response bias was excluded.<br />
Used a perceptual-aesthetic mood induction that increased mixed in open people.</p>
<p>Openness to experience is characterised by flexible and inclusive cognition. Here we investigated whether this extends to basic visual perception, such that open people combine information more flexibly, even at low-levels of perceptual processing. We used binocular rivalry, where the brain alternates between perceptual solutions and times where neither solution is fully suppressed, mixed percept. Study 1 showed that openness is positively associated with duration of mixed percept and ruled out the possibility of response bias. Study 2 showed that mixed percept increased following a positive mood induction particularly for open people. Overall, the results showed that openness is linked to differences in low-level visual perceptual experience. Further studies should investigate whether this may be driven by common neural processes.</p>
</li>
</ul>
</li>
</ul>
<h2>06549</h2>
<ul>
<li><em>now you see it, now you… seeing things that are hidden; failing to see things in plain sight. how magic exploits the everyday weirdness of perception</em><br />
vebjørn ekroll 2017<br />
<a href="https://aeon.co/essays/how-real-magic-happens-when-the-brain-sees-hidden-things">aeon.co/essays/how-real-magic-happens-when-the-brain-sees-hidden-things</a></li>
</ul>
<h2>06649</h2>
<ul>
<li>
<p><em>the order of disorder: deconstructing visual disorder and its effect on rule-breaking</em><br />
hiroki p. kotabe, omid kardan, marc g. berman 2016<br />
<a href="http://dx.doi.org/10.1037/xge0000240">xge0000240</a></p>
<ul>
<li>Disorderly environments are linked to disorderly behaviors. Broken windows theory (Wilson &amp; Kelling, 1982), an influential theory of crime and rule-breaking, assumes that scene-level social disorder cues (e.g., litter, graffiti) cause people to reason that they can get away with breaking rules. But what if part of the story is not about such complex social reasoning? Recent research suggests that basic visual disorder cues may be sufficient to encourage complex rule-breaking behavior. To test this hypothesis, we first conducted a set of experiments (Experiments 1–3) in which we identified basic visual disorder cues that generalize across visual stimuli with a variety of semantic content. Our results revealed that spatial features (e.g., nonstraight edges, asymmetry) are more important than color features (e.g., hue, saturation, value) for visual disorder. Exploiting this knowledge, we then reconstructed stimuli contrasted in terms of visual disorder, but absent of scene-level social disorder cues, to test whether visual disorder alone encourages cheating in a second set of experiments (Experiments 4 and 5). In these experiments, manipulating visual disorder increased the likelihood of cheating by up to 35% and the average magnitude of cheating by up to 87%. This work suggests that theories of rule-breaking that assume that complex social reasoning (e.g., about norms, policing, poverty) is necessary, should be reconsidered (e.g., Kelling &amp; Coles, 1997; Sampson &amp; Raudenbush, 2004). Furthermore, these experiments show that simple perceptual properties of the environment can affect complex behavior and sheds light on the extent to which our actions are within our control.</li>
</ul>
</li>
</ul>
<h2>06749</h2>
<ul>
<li>
<p><em>confirmation bias in human reinforcement learning: evidence from counterfactual feedback processing</em><br />
stefano palminteri et al. 2017<br />
<a href="https://doi.org/10.1371/journal.pcbi.1005684">doi.org/10.1371/journal.pcbi.1005684</a></p>
<ul>
<li>
<p>Previous studies suggest that <em>factual</em> learning, that is, learning from obtained outcomes, is biased, such that participants preferentially take into account positive, as compared to negative, prediction errors. However, whether or not the prediction error valence also affects <em>counterfactual</em> learning, that is, learning from forgone outcomes, is unknown. To address this question, we analysed the performance of two groups of participants on reinforcement learning tasks using a computational model that was adapted to test if prediction error valence influences learning. We carried out two experiments: in the factual learning experiment, participants learned from partial feedback (i.e., the outcome of the chosen option only); in the counterfactual learning experiment, participants learned from complete feedback information (i.e., the outcomes of both the chosen and unchosen option were displayed). In the factual learning experiment, we replicated previous findings of a valence-induced bias, whereby participants learned preferentially from positive, relative to negative, prediction errors. In contrast, for counterfactual learning, we found the opposite valence-induced bias: negative prediction errors were preferentially taken into account, relative to positive ones. When considering valence-induced bias in the context of both factual and counterfactual learning, it appears that people tend to preferentially take into account information that confirms their current choice.</p>
<p>While the investigation of decision-making biases has a long history in economics and psychology, learning biases have been much less systematically investigated. This is surprising as most of the choices we deal with in everyday life are recurrent, thus allowing learning to occur and therefore influencing future decision-making. Combining behavioural testing and computational modeling, here we show that the valence of an outcome biases both factual and counterfactual learning. When considering factual and counterfactual learning together, it appears that people tend to preferentially take into account information that confirms their current choice. Increasing our understanding of learning biases will enable the refinement of existing models of value-based decision-making.</p>
</li>
</ul>
</li>
</ul>
<h2>06849</h2>
<h2>06949</h2>
<h2>07049</h2>
<ul>
<li>
<p><em>pre–suasion: a revolutionary way to influence and persuade</em><br />
robert cialdini 2016 9781501109812</p>
<ul>
<li>the effectiveness of persuasive messages will be drastically affected by the type of opener experienced immediately in advance</li>
<li>Put people in a wary state of mind via that opener, and, driven by a desire for safety, a popularity-based appeal will soar, whereas a distinctiveness-based appeal will sink. But use it to put people in an amorous state of mind, and, driven by a consequent desire to stand out, the reverse will occur.</li>
<li>salience–importance confounding</li>
<li>focal–causal confounding</li>
<li>orientation reflex
<ul>
<li>“a persuasion-oriented producer, writer, or director needs to be concerned principally with shots and cuts”</li>
<li>“cuts are crucial to persuasive success because they can be manipulated to bring into focus the feature of a message the persuader believes to be most convincing—by shifting the scene to that feature. That cut will instigate an orienting response to the winning feature in audience members’ brains before they even experience it.”</li>
<li>create background of similar things draws attention to that which is different and hence perceived importance</li>
</ul>
</li>
<li>unresolved
<ul>
<li>mystery</li>
</ul>
</li>
<li>“the main purpose of speech is to direct listeners’ attention to a selected sector of reality. Once that is accomplished, the listeners’ existing associations to the now-spotlighted sector will take over to determine the reaction.”</li>
<li><em>influence: science and practice</em><br />
robert cialdini</li>
</ul>
</li>
<li>
<p><em>surprise, recipes for surprise, and social influence</em><br />
jeffrey loewenstein 2018<br />
<a href="http://dx.doi.org/10.1111/tops.12312">http://dx.doi.org/10.1111/tops.12312</a></p>
<ul>
<li>Surprising people can provide an opening for influencing them. Surprises garner attention, are arousing, are memorable, and can prompt shifts in understanding. Less noted is that, as a result, sur- prises can serve to persuade others by leading them to shifts in attitudes. Furthermore, because stories, pictures, and music can generate surprises and those can be widely shared, surprise can have broad social influence. People also tend to share surprising items with others, as anyone on social media has discovered. This means that in addition to broadcasting surprising information, surprising items can also spread through networks. The joint result is that surprise not only has individual effects on beliefs and attitudes but also collective effects on the content of culture. Items that generate sur- prise need not be random or accidental. There are predictable methods or recipes for generating surprise. One such recipe is discussed, the <em>repetition-break plot structure</em>, to explore the psychological and social possibilities of examining surprise. Recipes for surprise offer a useful means for under- standing how surprise works and offer prospects for harnessing surprise to a wide array of ends.</li>
</ul>
</li>
</ul>
<h2>07149</h2>
<ul>
<li>
<p><em>perceived entitlement causes discrimination against attractive job candidates in the domain of relatively less desirable jobs</em><br />
margaret lee et al. 2017<br />
<a href="http://dx.doi.org/10.1037/pspi0000114">dx.doi.org/10.1037/pspi0000114</a></p>
<ul>
<li>People generally hold positive stereotypes of physically attractive people and because of those stereotypes often treat them more favorably. However, we propose that some beliefs about attractive people, specifically, the perception that attractive individuals have a greater sense of entitlement than less attractive individuals, can result in negative treatment of attractive people. We examine this in the context of job selection and propose that for relatively less desirable jobs, attractive candidates will be discriminated against. We argue that the ascribed sense of entitlement to good outcomes leads to perceptions that attractive individuals are more likely to be dissatisfied working in relatively less desirable jobs. When selecting candidates for relatively less desirable jobs, decision makers try to ascertain whether a candidate would be satisfied in those jobs, and the stereotype of attractive individuals feeling entitled to good outcomes makes decision makers judge attractive candidates as more likely to be dissatisfied in relatively less (but not more) desirable jobs. Consequently, attractive candidates are discriminated against in the selection for relatively less desirable jobs. Four experiments found support for this theory. Our results suggest that different discriminatory processes operate when decision makers select among candidates for relatively less desirable jobs and that attractive people might be systematically discriminated against in a segment of the workforce.</li>
</ul>
</li>
</ul>
<h2>07249</h2>
<ul>
<li><em>’fiction is outperforming reality’: how youtube’s algorithm distorts truth</em><br />
paul lewis 2018<br />
<a href="https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth">https://www.theguardian.com/technology/2018/feb/02/how-youtubes-algorithm-distorts-truth</a></li>
</ul>
<h2>07349</h2>
<ul>
<li>
<p><em>déjà vu: an illusion of prediction</em><br />
anne m. cleary, alexander b. claxton 2018<br />
<a href="http://dx.doi.org/10.1177/0956797617743018">http://dx.doi.org/10.1177/0956797617743018</a></p>
<ul>
<li>Déjà vu is beginning to be scientifically understood as a memory phenomenon. Despite recent scientific advances, a remaining puzzle is the purported association between déjà vu and feelings of premonition. Building on research showing that déjà vu can be driven by an unrecalled memory of a past experience that relates to the current situation, we sought evidence of memory-based predictive ability during déjà vu states. Déjà vu did not lead to above-chance ability to predict the next turn in a navigational path resembling a previously experienced but unrecalled path (although such resemblance increased reports of déjà vu). However, déjà vu states were accompanied by increased feelings of knowing the direction of the next turn. The results suggest that feelings of premonition during déjà vu occur and can be illusory. Metacognitive bias brought on by the state itself may explain the peculiar association between déjà vu and the feeling of premonition.</li>
</ul>
</li>
</ul>
<h2>07449</h2>
<ul>
<li>
<p><em>rude color glasses: the contaminating effects of witnessed morning rudeness on perceptions and behaviors throughout the workday</em><br />
woolum, andrew et al. 2017<br />
<a href="http://psycnet.apa.org/doi/10.1037/apl0000247">http://psycnet.apa.org/doi/10.1037/apl0000247</a></p>
<ul>
<li>Using an experimental experience sampling design, we investigate how witnessing morning rudeness influences workers’ subsequent perceptions and behaviors throughout the workday. We posit that a single exposure to rudeness in the morning can contaminate employees’ perceptions of subsequent social interactions leading them to perceive greater workplace rudeness throughout their workday. We expect that these contaminated perceptions will have important ramifications for employees’ work behaviors. In a 10-day study of 81 professional and managerial employees, we find that witnessed morning rudeness leads to greater perceptions of workplace rudeness throughout the workday and that those perceptions, in turn, predict lower task performance and goal progress and greater interaction avoidance and psychological withdrawal. We also find that the contaminating effect of morning rudeness depends on core self-evaluations (CSE)—employees high (vs. low) in CSE are affected less by exposure to morning rudeness. We discuss implications for practice and theory.</li>
</ul>
</li>
</ul>
<h2>07549</h2>
<ul>
<li>
<p><em>expertise fails to attenuate gendered biases in judicial decision-making</em><br />
andrea l. miller 2018<br />
<a href="http://dx.doi.org/10.1177/1948550617741181">http://dx.doi.org/10.1177/1948550617741181</a></p>
<ul>
<li>Although the influence of gender ideology on lay decision-making has been established, it is not known to what extent expertise may mitigate gendered biases and improve decision-making quality. In a set of controlled experiments, trial court judges and laypeople evaluated a hypothetical child custody case and a hypothetical employment discrimination case. The role of expertise was tested in two ways: by comparing judges’ and laypeople’s decision-making and by examining relative differences in expertise among judges. Judges were no less influenced by litigant gender and by their own gender ideology than the lay sample. Judges with greater subject-matter expertise were also no less influenced by gender ideology than other judges. In some cases, expertise was associated with greater, not less, bias. The results of this study suggest that expertise does not attenuate gendered biases in legal decision-making.</li>
</ul>
</li>
</ul>
<h2>07649</h2>
<h2>07749</h2>
<ul>
<li>
<p><em>prevalence-induced concept change in human judgment</em><br />
david e. levari et al. 2018<br />
<a href="http://dx.doi.org/10.1126/science.aap8731">http://dx.doi.org/10.1126/science.aap8731</a></p>
<ul>
<li>Why do some social problems seem so intractable? In a series of experiments, we show that people often respond to decreases in the prevalence of a stimulus by expanding their concept of it. When blue dots became rare, participants began to see purple dots as blue; when threatening faces became rare, participants began to see neutral faces as threatening; and when unethical requests became rare, participants began to see innocuous requests as unethical. This “prevalence-induced concept change” occurred even when participants were forewarned about it and even when they were instructed and paid to resist it. Social problems may seem intractable in part because reductions in their prevalence lead people to see more of them.</li>
</ul>
</li>
</ul>
<h2>07849</h2>
<h2>07949</h2>
<h2>08049</h2>
<h2>08149</h2>
<h2>08249</h2>
<h2>08349</h2>
<h2>08449</h2>
<h2>08549</h2>
<h2>08649</h2>
<h2>08749</h2>
<ul>
<li>
<p><em>unconventional consumption methods and enjoying things consumed: recapturing the “first-time” experience</em><br />
ed o’brien, robert w. smith 2018<br />
<a href="http://dx.doi.org/10.1177/0146167218779823">http://dx.doi.org/10.1177/0146167218779823</a></p>
<ul>
<li>People commonly lament the inability to re-experience familiar things as they were first experienced. Four experiments suggest that consuming familiar things in new <em>ways</em> can disrupt adaptation and revitalize enjoyment. Participants better enjoyed the same familiar food (Experiment 1), drink (Experiment 2), and video (Experiments 3a-3b) simply when re-experiencing the entity via unusual means (e.g., eating popcorn using chopsticks vs. hands). This occurs because unconventional methods invite an immersive “first-time” perspective on the consumption object: boosts in enjoyment were mediated by revitalized immersion into the consumption experience and were moderated by time such that they were strongest when using unconventional methods for the first time (Experiments 1-2); likewise, unconventional methods that actively disrupted immersion did not elicit the boost, despite being novel (Experiments 3a-3b). Before abandoning once-enjoyable entities, knowing to consume old things in new <em>ways</em> (vs. attaining new things altogether) might temporarily restore enjoyment and postpone wasteful replacement.</li>
</ul>
</li>
</ul>
<h2>08849</h2>
<h2>08949</h2>
<h2>09049</h2>
<ul>
<li>
<p><em>mechanosensory-based phase coding of odor identity in the olfactory bulb</em><br />
ryo iwata et al. 2017<br />
<a href="http://dx.doi.org/10.1016/j.neuron.2017.11.008">http://dx.doi.org/10.1016/j.neuron.2017.11.008</a></p>
<ul>
<li>
<p>•Mechanosensation in olfactory sensory neurons generates sniff-coupled oscillations<br />
•Phase coding in mitral/tufted cells distinguishes odor from mechanical signals<br />
•Phase coding is more stable than rate coding across time and odor concentrations<br />
•The loss of mechanosensory-based oscillations impairs robust phase coding of odors</p>
<p>Mitral and tufted (M/T) cells in the olfactory bulb produce rich temporal patterns of activity in response to different odors. However, it remains unknown how these temporal patterns are generated and how they are utilized in olfaction. Here we show that temporal patterning effectively discriminates between the two sensory modalities detected by olfactory sensory neurons (OSNs): odor and airflow-driven mechanical signals. Sniff-induced mechanosensation generates glomerulus-specific oscillatory activity in M/T cells, whose phase was invariant across airflow speed. In contrast, odor stimulation caused phase shifts (phase coding). We also found that odor-evoked phase shifts are concentration invariant and stable across multiple sniff cycles, contrary to the labile nature of rate coding. The loss of oscillatory mechanosensation impaired the precision and stability of phase coding, demonstrating its role in olfaction. We propose that phase, not rate, coding is a robust encoding strategy of odor identity and is ensured by airflow-induced mechanosensation in OSNs.</p>
</li>
</ul>
</li>
<li>
<p><em>volatile biomarkers of symptomatic and asymptomatic malaria infection in humans</em><br />
consuelo m. de moraes et al. 2018<br />
<a href="http://dx.doi.org/10.1073/pnas.1801512115">http://dx.doi.org/10.1073/pnas.1801512115</a></p>
<ul>
<li>Malaria elimination efforts are hindered by the prevalence of asymptomatic infections, which frequently go undetected and untreated. Consequently, there is a pressing need for improved diagnostic screening methods. Based on extensive collections of skin odors from human populations in Kenya, we report broad and consistent effects of malaria infection on human volatile emissions. Furthermore, we found that predictive models based on machine learning algorithms reliably determined infection status based on volatile biomarkers and, critically, identified asymptomatic infections with 100% sensitivity, even in the case of low-level infections not detectable by microscopy. These findings suggest that volatile biomarkers have significant potential for the development of robust, noninvasive screening methods for detecting symptomatic and asymptomatic malaria infections under field conditions.</li>
</ul>
</li>
</ul>
<h2>09149</h2>
<ul>
<li>from lecture notes (origin unknown)
<ul>
<li>non-motile primary cilium sensory cells in mammals as mechanoreceptors</li>
<li>• ruffini corpuscles: touch, pressure. slow adaptation. respond to steady displacement.<br />
• hair follicle receptors: hair displacement, rapid adaptation<br />
• meissner corpuscles: touch, vibration, rapid adaptation (velocity<br />
detection) (= krause’s end bulbs in non-primate mammals)<br />
• paccinian corpuscles: touch, vibration, very fast adaption (acceleration detection)</li>
</ul>
</li>
</ul>
<h2>09249</h2>
<h2>09349</h2>
<ul>
<li><em>how cotton production in medieval china unravelled patriarchy</em><br />
melanie meng xue 2018<br />
<a href="https://aeon.co/ideas/how-cotton-production-in-medieval-china-unravelled-patriarchy">https://aeon.co/ideas/how-cotton-production-in-medieval-china-unravelled-patriarchy</a></li>
</ul>
<h2>09449</h2>
<h2>09549</h2>
<h2>09649</h2>
<h2>09749</h2>
<ul>
<li>not yet read
<ul>
<li>
<p><em>champions of illusion: the science behind mind-boggling images and mystifying brain puzzles</em><br />
susana martinez-conde, stephen macknik 2017</p>
</li>
<li>
<p><em>reading people: how seeing the world through the lens of personality changes everything</em><br />
anne bogel 2017</p>
<ul>
<li>author is devout christian?</li>
</ul>
</li>
<li>
<p><em>seeing what others don’t: the remarkable ways we gain insights</em><br />
gary klein 2013</p>
</li>
<li>
<p><em>how to be more interesting</em><br />
edward de bono 2010</p>
</li>
<li>
<p><em>yes! 50 secrets from the science of persuasion</em><br />
noah goldstein, steve martin, robert cialdini 2007</p>
</li>
<li>
<p><em>blindspot: hidden biases of good people</em><br />
mahzarin banaji &amp; anthony greenwald 2013</p>
</li>
<li>
<p><em>race on the brain: what implicit bias gets wrong about the struggle for racial justice</em><br />
jonathan kahn 2017</p>
</li>
<li>
<p><em>is science racist?</em><br />
jonathan marks 2017</p>
</li>
<li>
<p><em>less than human: why we demean, enslave, and exterminate others</em><br />
david livingstone smith 2012</p>
</li>
<li>
<p><em>coming to our senses: perceiving complexity to avoid catastrophes</em><br />
viki mccabe 2014</p>
</li>
<li>
<p><em>war of the worldviews: where science and spirituality meet and do not</em><br />
deepak chopra, leonard mlodinow 2012</p>
</li>
<li>
<p><em>the smell of fresh rain: the unexpected pleasures of our most elusive sense</em> barney shaw 2017</p>
</li>
<li>
<p><em>simplexity: why simple things become complex (and how complex things can be made simple)</em><br />
jeffrey kluger 2008</p>
</li>
<li>
<p><em>our senses: an immersive experience</em><br />
rob desalle 2018</p>
</li>
<li>
<p><em>the power of intuition: how to use your gut feelings to make better decisions at work</em><br />
gary klein 2004</p>
</li>
<li>
<p><em>the mind is flat: the illusion of mental depth and the improvised mind</em><br />
nick chater 2018</p>
</li>
<li>
<p><em>the forgetting machine: memory, perception, and the “jennifer aniston neuron”</em><br />
rodrigo quian quiroga 2017</p>
</li>
<li>
<p><em>the intuitive way the definitive guide to increasing your awareness</em><br />
penney peirce 1997</p>
</li>
<li>
<p><em>the confidence game: the psychology of the con and why we fall for it every time</em><br />
konnikova maria 2017</p>
</li>
<li>
<p><em>joyful: the surprising power of ordinary things to create extraordinary happiness</em><br />
ingrid fetell lee 2018</p>
</li>
</ul>
</li>
</ul>
<h2>09849</h2>
<h2>09949</h2>
<h2>04949</h2>
<h2>04849</h2>
<ul>
<li>Huxley had a similar–sounding visual recall issue as I have.</li>
</ul>
<h2>04749</h2>
<h2>04649</h2>
<h2>04549</h2>
<h2>04449</h2>
<h2>04349</h2>
<h2>04249</h2>
<h2>04149</h2>
<h2>04049</h2>
<h2>03949</h2>
<h2>03849</h2>
<h2>03749</h2>
<h2>03649</h2>
<h2>03549</h2>
<h2>03449</h2>
<h2>03349</h2>
<h2>03249</h2>
<h2>03149</h2>
<h2>03049</h2>
<h2>02949</h2>
<h2>02849</h2>
<h2>02749</h2>
<h2>02649</h2>
<h2>02549</h2>
<h2>02449</h2>
<h2>02349</h2>
<h2>02249</h2>
<h2>02149</h2>
<h2>02049</h2>
<h2>01949</h2>
<h2>01849</h2>
<h2>01749</h2>
<h2>01649</h2>
<h2>01549</h2>
<h2>01449</h2>
<h2>01349</h2>
<h2>01249</h2>
<h2>01149</h2>
<h2>01049</h2>
<h2>00949</h2>
<h2>00849</h2>
<h2>00749</h2>
<ul>
<li>a person can be greatly aware one moment but almost unaware the next</li>
</ul>
<h2>00649</h2>
<ul>
<li>there are no absolutes, no truly right, no truly wrong. we should not judge ourselves or others harshly — for even our best intentions and plans may not be as close to responsible as we thought they were.</li>
</ul>
<h2>00549</h2>
<ul>
<li>
<p><em>world too small</em><br />
when someone's world becomes too small, that is when problems start. They start to attribute even accidental consequences to alleged malicious behaviour in the people around them.</p>
</li>
<li>
<p>our perspective sometimes narrows, and it is then that we are more likely to abuse.</p>
</li>
<li>
<p>when our perspective narrows, it becomes harder to break out of our current outlook, to learn of the changing shape of reality, to look beyond what we already believe.</p>
</li>
</ul>
<h2>00449</h2>
<ul>
<li>dyslexia
<ul>
<li>dyslexic in dream: I could read the numbers but couldn't quite make out the letters; apparently this is what happens in dyslexia. could it be that in dreams I am dyslexic? apparently not all people are dyslexic in their dreams, at least not all the time. so could it be that when a certain part of the brain is resting in sleep, it resembles dyslexia?</li>
<li>could it be that dream states are because certain parts of the brain are resting and we may be able to correlate different types of dream states with different parts of the brain resting?</li>
<li>maybe dyslexics have a certain kind of synaesthesia which mixes letters with colours and movement. when colorised filters applied, the colour no longer salient so movement also suppressed. the type of coloured filter required to block the so-called dyslexia varies with the kind of so-called synaesthesia.</li>
</ul>
</li>
</ul>
<h2>00349</h2>
<ul>
<li>Instinct
<ul>
<li>I have a strange premonition that something is going to happen soon in the world, and we won't be able to contact each other. I want you to know I will be thinking of you. here are my notes so far, I don't know if they'll be any help…</li>
<li>when I was young, I felt intuitively that something was awfully wrong with our society. after another twenty years I understood how to communicate this in language</li>
<li>trust your instincts. if they tell you to be wary, that's okay.</li>
<li>Instinct is a name given to processes we do not yet understand. Perception may be a better name for it. We can perceive and act on a situation even if we don't understand how to explain it in words.</li>
<li>Test your perception and then trust it. A way to approach this is to try to understand the physical filters on your perception, and your mental filters such as bias and judgement. Then we can understand some of the obstacles in the way of our perception and can trust our own perception.</li>
<li>people minimise what they don't understand. most want conscious explanation of hunches, feelings, premonitions before they can actually be articulated by our conscious brains, that is the very definition of premonition. they devalue this because they don't understand it and don't trust that we can understand something is useful when they can't. they demand that we trust them but they need to uphold the corresponding reponsibility. at the moment they don't so it is why we don't like it even though we could not find the words to express it before
<ul>
<li>a crucial difference in outlook and expectation that exists and is self–perpetuating</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2>00249</h2>
<ul>
<li><em>see–feel–value</em><br />
literally cannot see or feel something (like risk, climate change), so most people can not value it</li>
</ul>
<h2>00149</h2>
<h2>00049</h2>
<ul>
<li>indium In (indigo, from blue spectrum lines)</li>
<li>candy smith–foster
<ul>
<li>crossing a railway bridge</li>
<li>parrot</li>
</ul>
</li>
<li>DI</li>
</ul>

</div>

</body>
</html>
